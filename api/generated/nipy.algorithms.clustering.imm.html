
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Neuroimaging in Python &#8212; NIPY Documentation</title>
    <link rel="stylesheet" href="../../_static/nipy.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="algorithms.clustering.utils" href="nipy.algorithms.clustering.utils.html" />
    <link rel="prev" title="algorithms.clustering.hierarchical_clustering" href="nipy.algorithms.clustering.hierarchical_clustering.html" />
  <meta name="keywords" content="nipy, neuroimaging, python, neuroscience, time
				 series">

  </head><body>
<div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
 <a href="../../index.html">
  <img src="../../_static/reggie2.png" alt="NIPY logo"  border="0" />
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="nipy.algorithms.clustering.utils.html" title="algorithms.clustering.utils"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nipy.algorithms.clustering.hierarchical_clustering.html" title="algorithms.clustering.hierarchical_clustering"
             accesskey="P">previous</a> |</li>
  <li><a href="../../index.html">NIPY home</a> |&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="../../documentation.html" >NIPY documentation</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" accesskey="U">API</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">

  
<h4> Site Navigation </h4>
  <ul>
    <li><a href="../../documentation.html">Documentation</a></li>
    <li><a href="../../devel/index.html">Development</a></li>
  </ul>

<h4> NIPY Community </h4>
  <ul class="simple">
    <li><a class="reference external"
	href="http://nipy.org/">Community Home</a></li>
    <li><a class="reference external"
	href="http://nipy.org/project-directory">NIPY Projects</a></li>
    <li><a class="reference external"
	href="https://mail.python.org/mailman/listinfo/neuroimaging">Mailing List</a></li>
    <li><a class="reference external"
	href="license.html">License</a></li>
  </ul>

<h4> Github repo </h4>
  <ul class="simple">
    <li><a class="reference external"
	href="http://github.com/nipy/nipy/">Nipy Github</a></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">algorithms.clustering.imm</a><ul>
<li><a class="reference internal" href="#module-algorithms-clustering-imm">Module: <code class="xref py py-mod docutils literal notranslate"><span class="pre">algorithms.clustering.imm</span></code></a></li>
<li><a class="reference internal" href="#classes">Classes</a><ul>
<li><a class="reference internal" href="#imm"><code class="xref py py-class docutils literal notranslate"><span class="pre">IMM</span></code></a></li>
<li><a class="reference internal" href="#mixedimm"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedIMM</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#functions">Functions</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nipy.algorithms.clustering.hierarchical_clustering.html"
                        title="previous chapter">algorithms.clustering.hierarchical_clustering</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nipy.algorithms.clustering.utils.html"
                        title="next chapter">algorithms.clustering.utils</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/api/generated/nipy.algorithms.clustering.imm.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="algorithms-clustering-imm">
<h1>algorithms.clustering.imm<a class="headerlink" href="#algorithms-clustering-imm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-algorithms-clustering-imm">
<h2>Module: <code class="xref py py-mod docutils literal notranslate"><span class="pre">algorithms.clustering.imm</span></code><a class="headerlink" href="#module-algorithms-clustering-imm" title="Permalink to this headline">¶</a></h2>
<p>Inheritance diagram for <code class="docutils literal notranslate"><span class="pre">nipy.algorithms.clustering.imm</span></code>:</p>
<div class="graphviz"><img src="../../_images/inheritance-be63f17ad7f9d69b310c5e7663f5dc8055c78da3.png" alt="Inheritance diagram of nipy.algorithms.clustering.imm" usemap="#inheritance317d710708" class="inheritance graphviz" /></div>
<map id="inheritance317d710708" name="inheritance317d710708">
<area shape="rect" id="node1" href="nipy.algorithms.clustering.bgmm.html#nipy.algorithms.clustering.bgmm.BGMM" target="_top" title="This class implements Bayesian GMMs" alt="" coords="199,5,360,30"/>
<area shape="rect" id="node3" href="#nipy.algorithms.clustering.imm.IMM" target="_top" title="The class implements Infinite Gaussian Mixture model" alt="" coords="408,5,544,30"/>
<area shape="rect" id="node2" href="nipy.algorithms.clustering.gmm.html#nipy.algorithms.clustering.gmm.GMM" target="_top" title="Standard GMM." alt="" coords="5,5,151,30"/>
<area shape="rect" id="node4" href="#nipy.algorithms.clustering.imm.MixedIMM" target="_top" title="Particular IMM with an additional null class." alt="" coords="592,5,763,30"/>
</map><span class="target" id="module-nipy.algorithms.clustering.imm"></span><p>Infinite mixture model : A generalization of Bayesian mixture models
with an unspecified number of classes</p>
</div>
<div class="section" id="classes">
<h2>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="imm">
<h3><a class="reference internal" href="#nipy.algorithms.clustering.imm.IMM" title="nipy.algorithms.clustering.imm.IMM"><code class="xref py py-class docutils literal notranslate"><span class="pre">IMM</span></code></a><a class="headerlink" href="#imm" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="nipy.algorithms.clustering.imm.IMM">
<em class="property">class </em><code class="sig-prename descclassname">nipy.algorithms.clustering.imm.</code><code class="sig-name descname">IMM</code><span class="sig-paren">(</span><em class="sig-param">alpha=0.5</em>, <em class="sig-param">dim=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="nipy.algorithms.clustering.bgmm.html#nipy.algorithms.clustering.bgmm.BGMM" title="nipy.algorithms.clustering.bgmm.BGMM"><code class="xref py py-class docutils literal notranslate"><span class="pre">nipy.algorithms.clustering.bgmm.BGMM</span></code></a></p>
<p>The class implements Infinite Gaussian Mixture model
or Dirichlet Proces Mixture Model.
This simply a generalization of Bayesian Gaussian Mixture Models
with an unknown number of classes.</p>
<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">alpha=0.5</em>, <em class="sig-param">dim=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>alpha: float, optional,</strong></dt><dd><p>the parameter for cluster creation</p>
</dd>
<dt><strong>dim: int, optional,</strong></dt><dd><p>the dimension of the the data</p>
</dd>
<dt><strong>Note: use the function set_priors() to set adapted priors</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.average_log_like">
<code class="sig-name descname">average_log_like</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">tiny=1e-15</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.average_log_like" title="Permalink to this definition">¶</a></dt>
<dd><p>returns the averaged log-likelihood of the mode for the dataset x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x:  array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>tiny = 1.e-15: a small constant to avoid numerical singularities</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.bayes_factor">
<code class="sig-name descname">bayes_factor</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">nperm=0</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.bayes_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the Bayes Factor of the current model using Chib’s method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (nb_samples,dim)</strong></dt><dd><p>the data from which bic is computed</p>
</dd>
<dt><strong>z: array of shape (nb_samples), type = np.int</strong></dt><dd><p>the corresponding classification</p>
</dd>
<dt><strong>nperm=0: int</strong></dt><dd><p>the number of permutations to sample
to model the label switching issue
in the computation of the Bayes Factor
By default, exhaustive permutations are used</p>
</dd>
<dt><strong>verbose=0: verbosity mode</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>bf (float) the computed evidence (Bayes factor)</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>See: Marginal Likelihood from the Gibbs Output
Journal article by Siddhartha Chib;
Journal of the American Statistical Association, Vol. 90, 1995</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.bic">
<code class="sig-name descname">bic</code><span class="sig-paren">(</span><em class="sig-param">like</em>, <em class="sig-param">tiny=1e-15</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.bic" title="Permalink to this definition">¶</a></dt>
<dd><p>Computation of bic approximation of evidence</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>like, array of shape (n_samples, self.k)</strong></dt><dd><p>component-wise likelihood</p>
</dd>
<dt><strong>tiny=1.e-15, a small constant to avoid numerical singularities</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>the bic value, float</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.check">
<code class="sig-name descname">check</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.check" title="Permalink to this definition">¶</a></dt>
<dd><p>Checking the shape of sifferent matrices involved in the model</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.check_x">
<code class="sig-name descname">check_x</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.check_x" title="Permalink to this definition">¶</a></dt>
<dd><p>essentially check that x.shape[1]==self.dim</p>
<p>x is returned with possibly reshaping</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.conditional_posterior_proba">
<code class="sig-name descname">conditional_posterior_proba</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">perm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.conditional_posterior_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the probability of the current parameters of self
given x and z</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (nb_samples, dim),</strong></dt><dd><p>the data from which bic is computed</p>
</dd>
<dt><strong>z: array of shape (nb_samples), type = np.int,</strong></dt><dd><p>the corresponding classification</p>
</dd>
<dt><strong>perm: array ok shape(nperm, self.k),typ=np.int, optional</strong></dt><dd><p>all permutation of z under which things will be recomputed
By default, no permutation is performed</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.cross_validated_update">
<code class="sig-name descname">cross_validated_update</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">plike</em>, <em class="sig-param">kfold=10</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.cross_validated_update" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a step in the sampling procedure
that uses internal corss_validation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape(n_samples, dim),</strong></dt><dd><p>the input data</p>
</dd>
<dt><strong>z: array of shape(n_samples),</strong></dt><dd><p>the associated membership variables</p>
</dd>
<dt><strong>plike: array of shape(n_samples),</strong></dt><dd><p>the likelihood under the prior</p>
</dd>
<dt><strong>kfold: int, or array of shape(n_samples), optional,</strong></dt><dd><p>folds in the cross-validation loop</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like: array od shape(n_samples),</strong></dt><dd><p>the (cross-validated) likelihood of the data</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.estimate">
<code class="sig-name descname">estimate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">niter=100</em>, <em class="sig-param">delta=0.0001</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.estimate" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimation of the model given a dataset x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,dim)</strong></dt><dd><p>the data from which the model is estimated</p>
</dd>
<dt><strong>niter=100: maximal number of iterations in the estimation process</strong></dt><dd></dd>
<dt><strong>delta = 1.e-4: increment of data likelihood at which</strong></dt><dd><p>convergence is declared</p>
</dd>
<dt><strong>verbose=0: verbosity mode</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>bic</strong><span class="classifier">an asymptotic approximation of model evidence</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.evidence">
<code class="sig-name descname">evidence</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">nperm=0</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.evidence" title="Permalink to this definition">¶</a></dt>
<dd><p>See bayes_factor(self, x, z, nperm=0, verbose=0)</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.guess_priors">
<code class="sig-name descname">guess_priors</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">nocheck=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.guess_priors" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the priors in order of having them weakly uninformative
this is from  Fraley and raftery;
Journal of Classification 24:155-181 (2007)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x, array of shape (nb_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>nocheck: boolean, optional,</strong></dt><dd><p>if nocheck==True, check is skipped</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.guess_regularizing">
<code class="sig-name descname">guess_regularizing</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">bcheck=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.guess_regularizing" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the regularizing priors as weakly informative
according to Fraley and raftery;
Journal of Classification 24:155-181 (2007)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>initialize z using a k-means algorithm, then upate the parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (nb_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.initialize_and_estimate">
<code class="sig-name descname">initialize_and_estimate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z=None</em>, <em class="sig-param">niter=100</em>, <em class="sig-param">delta=0.0001</em>, <em class="sig-param">ninit=1</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.initialize_and_estimate" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimation of self given x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,dim)</strong></dt><dd><p>the data from which the model is estimated</p>
</dd>
<dt><strong>z = None: array of shape (n_samples)</strong></dt><dd><p>a prior labelling of the data to initialize the computation</p>
</dd>
<dt><strong>niter=100: maximal number of iterations in the estimation process</strong></dt><dd></dd>
<dt><strong>delta = 1.e-4: increment of data likelihood at which</strong></dt><dd><p>convergence is declared</p>
</dd>
<dt><strong>ninit=1: number of initialization performed</strong></dt><dd><p>to reach a good solution</p>
</dd>
<dt><strong>verbose=0: verbosity mode</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>the best model is returned</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.likelihood">
<code class="sig-name descname">likelihood</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">plike=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>return the likelihood of the model for the data x
the values are weighted by the components weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples, self.dim),</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>plike: array os shape (n_samples), optional,x</strong></dt><dd><p>the desnity of each point under the prior</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like, array of shape(nbitem,self.k)</strong></dt><dd></dd>
<dt><strong>component-wise likelihood</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.likelihood_under_the_prior">
<code class="sig-name descname">likelihood_under_the_prior</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.likelihood_under_the_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the likelihood of x under the prior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x, array of shape (self.n_samples,self.dim)</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>w, the likelihood of x under the prior model (unweighted)</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.map_label">
<code class="sig-name descname">map_label</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">like=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.map_label" title="Permalink to this definition">¶</a></dt>
<dd><p>return the MAP labelling of x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,dim)</strong></dt><dd><p>the data under study</p>
</dd>
<dt><strong>like=None array of shape(n_samples,self.k)</strong></dt><dd><p>component-wise likelihood
if like==None, it is recomputed</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>z: array of shape(n_samples): the resulting MAP labelling</strong></dt><dd><p>of the rows of x</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.mixture_likelihood">
<code class="sig-name descname">mixture_likelihood</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.mixture_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the likelihood of the mixture for x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.plugin">
<code class="sig-name descname">plugin</code><span class="sig-paren">(</span><em class="sig-param">means</em>, <em class="sig-param">precisions</em>, <em class="sig-param">weights</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.plugin" title="Permalink to this definition">¶</a></dt>
<dd><p>Set manually the weights, means and precision of the model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>means: array of shape (self.k,self.dim)</strong></dt><dd></dd>
<dt><strong>precisions:  array of shape (self.k,self.dim,self.dim)</strong></dt><dd><p>or (self.k, self.dim)</p>
</dd>
<dt><strong>weights: array of shape (self.k)</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.pop">
<code class="sig-name descname">pop</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.pop" title="Permalink to this definition">¶</a></dt>
<dd><p>compute the population, i.e. the statistics of allocation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>z array of shape (nb_samples), type = np.int</strong></dt><dd><p>the allocation variable</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>hist</strong><span class="classifier">array shape (self.k) count variable</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.probability_under_prior">
<code class="sig-name descname">probability_under_prior</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.probability_under_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the probability of the current parameters of self
given the priors</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.reduce">
<code class="sig-name descname">reduce</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.reduce" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce the assignments by removing empty clusters and update self.k</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>z: array of shape(n),</strong></dt><dd><p>a vector of membership variables changed in place</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>z: the remapped values</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">niter=1</em>, <em class="sig-param">sampling_points=None</em>, <em class="sig-param">init=False</em>, <em class="sig-param">kfold=None</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>sample the indicator and parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples, self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>niter: int,</strong></dt><dd><p>the number of iterations to perform</p>
</dd>
<dt><strong>sampling_points: array of shape(nbpoints, self.dim), optional</strong></dt><dd><p>points where the likelihood will be sampled
this defaults to x</p>
</dd>
<dt><strong>kfold: int or array, optional,</strong></dt><dd><p>parameter of cross-validation control
by default, no cross-validation is used
the procedure is faster but less accurate</p>
</dd>
<dt><strong>verbose=0: verbosity mode</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>likelihood: array of shape(nbpoints)</strong></dt><dd><p>total likelihood of the model</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.sample_and_average">
<code class="sig-name descname">sample_and_average</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">niter=1</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.sample_and_average" title="Permalink to this definition">¶</a></dt>
<dd><p>sample the indicator and parameters
the average values for weights,means, precisions are returned</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x = array of shape (nb_samples,dim)</strong></dt><dd><p>the data from which bic is computed</p>
</dd>
<dt><strong>niter=1: number of iterations</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>weights: array of shape (self.k)</strong></dt><dd></dd>
<dt><strong>means: array of shape (self.k,self.dim)</strong></dt><dd></dd>
<dt><strong>precisions:  array of shape (self.k,self.dim,self.dim)</strong></dt><dd><p>or (self.k, self.dim)
these are the average parameters across samplings</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>All this makes sense only if no label switching as occurred so this is
wrong in general (asymptotically).</p>
<p>fix: implement a permutation procedure for components identification</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.sample_indicator">
<code class="sig-name descname">sample_indicator</code><span class="sig-paren">(</span><em class="sig-param">like</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.sample_indicator" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample the indicator from the likelihood</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>like: array of shape (nbitem,self.k)</strong></dt><dd><p>component-wise likelihood</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>z: array of shape(nbitem): a draw of the membership variable</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The behaviour is different from standard bgmm in that z can take
arbitrary values</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.set_constant_densities">
<code class="sig-name descname">set_constant_densities</code><span class="sig-paren">(</span><em class="sig-param">prior_dens=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.set_constant_densities" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the null and prior densities as constant
(assuming a compact domain)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>prior_dens: float, optional</strong></dt><dd><p>constant for the prior density</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.set_priors">
<code class="sig-name descname">set_priors</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.set_priors" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the priors in order of having them weakly uninformative
this is from  Fraley and raftery;
Journal of Classification 24:155-181 (2007)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x, array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.show">
<code class="sig-name descname">show</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">gd</em>, <em class="sig-param">density=None</em>, <em class="sig-param">axes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.show" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to plot a GMM, still in progress
Currently, works only in 1D and 2D</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape(n_samples, dim)</strong></dt><dd><p>the data under study</p>
</dd>
<dt><strong>gd: GridDescriptor instance</strong></dt><dd></dd>
<dt><strong>density: array os shape(prod(gd.n_bins))</strong></dt><dd><p>density of the model one the discrete grid implied by gd
by default, this is recomputed</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.show_components">
<code class="sig-name descname">show_components</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">gd</em>, <em class="sig-param">density=None</em>, <em class="sig-param">mpaxes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.show_components" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to plot a GMM – Currently, works only in 1D</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape(n_samples, dim)</strong></dt><dd><p>the data under study</p>
</dd>
<dt><strong>gd: GridDescriptor instance</strong></dt><dd></dd>
<dt><strong>density: array os shape(prod(gd.n_bins))</strong></dt><dd><p>density of the model one the discrete grid implied by gd
by default, this is recomputed</p>
</dd>
<dt><strong>mpaxes: axes handle to make the figure, optional,</strong></dt><dd><p>if None, a new figure is created</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.simple_update">
<code class="sig-name descname">simple_update</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">plike</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.simple_update" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>This is a step in the sampling procedure</p>
</div></blockquote>
<p>that uses internal corss_validation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape(n_samples, dim),</strong></dt><dd><p>the input data</p>
</dd>
<dt><strong>z: array of shape(n_samples),</strong></dt><dd><p>the associated membership variables</p>
</dd>
<dt><strong>plike: array of shape(n_samples),</strong></dt><dd><p>the likelihood under the prior</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like: array od shape(n_samples),</strong></dt><dd><p>the likelihood of the data</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.test">
<code class="sig-name descname">test</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">tiny=1e-15</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the log-likelihood of the mixture for x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>ll: array of shape(n_samples)</strong></dt><dd><p>the log-likelihood of the rows of x</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z=None</em>, <em class="sig-param">niter=100</em>, <em class="sig-param">delta=0.0001</em>, <em class="sig-param">ninit=1</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Idem initialize_and_estimate</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.unweighted_likelihood">
<code class="sig-name descname">unweighted_likelihood</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.unweighted_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>return the likelihood of each data for each component
the values are not weighted by the component weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like, array of shape(n_samples,self.k)</strong></dt><dd><p>unweighted component-wise likelihood</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Hopefully faster</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.unweighted_likelihood_">
<code class="sig-name descname">unweighted_likelihood_</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.unweighted_likelihood_" title="Permalink to this definition">¶</a></dt>
<dd><p>return the likelihood of each data for each component
the values are not weighted by the component weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like, array of shape(n_samples,self.k)</strong></dt><dd><p>unweighted component-wise likelihood</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update function (draw a sample of the IMM parameters)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>z array of shape (n_samples), type = np.int</strong></dt><dd><p>the corresponding classification</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.update_means">
<code class="sig-name descname">update_means</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.update_means" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the allocation vector z,
and the corresponding data x,
resample the mean</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (nb_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>z: array of shape (nb_samples), type = np.int</strong></dt><dd><p>the corresponding classification</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.update_precisions">
<code class="sig-name descname">update_precisions</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.update_precisions" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the allocation vector z,
and the corresponding data x,
resample the precisions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (nb_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>z array of shape (nb_samples), type = np.int</strong></dt><dd><p>the corresponding classification</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.IMM.update_weights">
<code class="sig-name descname">update_weights</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.IMM.update_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the allocation vector z, resmaple the weights parameter</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>z array of shape (n_samples), type = np.int</strong></dt><dd><p>the allocation variable</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="mixedimm">
<h3><a class="reference internal" href="#nipy.algorithms.clustering.imm.MixedIMM" title="nipy.algorithms.clustering.imm.MixedIMM"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedIMM</span></code></a><a class="headerlink" href="#mixedimm" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="nipy.algorithms.clustering.imm.MixedIMM">
<em class="property">class </em><code class="sig-prename descclassname">nipy.algorithms.clustering.imm.</code><code class="sig-name descname">MixedIMM</code><span class="sig-paren">(</span><em class="sig-param">alpha=0.5</em>, <em class="sig-param">dim=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nipy.algorithms.clustering.imm.IMM" title="nipy.algorithms.clustering.imm.IMM"><code class="xref py py-class docutils literal notranslate"><span class="pre">nipy.algorithms.clustering.imm.IMM</span></code></a></p>
<p>Particular IMM with an additional null class.
The data is supplied together
with a sample-related probability of being under the null.</p>
<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">alpha=0.5</em>, <em class="sig-param">dim=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>alpha: float, optional,</strong></dt><dd><p>the parameter for cluster creation</p>
</dd>
<dt><strong>dim: int, optional,</strong></dt><dd><p>the dimension of the the data</p>
</dd>
<dt><strong>Note: use the function set_priors() to set adapted priors</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.average_log_like">
<code class="sig-name descname">average_log_like</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">tiny=1e-15</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.average_log_like" title="Permalink to this definition">¶</a></dt>
<dd><p>returns the averaged log-likelihood of the mode for the dataset x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x:  array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>tiny = 1.e-15: a small constant to avoid numerical singularities</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.bayes_factor">
<code class="sig-name descname">bayes_factor</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">nperm=0</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.bayes_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the Bayes Factor of the current model using Chib’s method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (nb_samples,dim)</strong></dt><dd><p>the data from which bic is computed</p>
</dd>
<dt><strong>z: array of shape (nb_samples), type = np.int</strong></dt><dd><p>the corresponding classification</p>
</dd>
<dt><strong>nperm=0: int</strong></dt><dd><p>the number of permutations to sample
to model the label switching issue
in the computation of the Bayes Factor
By default, exhaustive permutations are used</p>
</dd>
<dt><strong>verbose=0: verbosity mode</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>bf (float) the computed evidence (Bayes factor)</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>See: Marginal Likelihood from the Gibbs Output
Journal article by Siddhartha Chib;
Journal of the American Statistical Association, Vol. 90, 1995</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.bic">
<code class="sig-name descname">bic</code><span class="sig-paren">(</span><em class="sig-param">like</em>, <em class="sig-param">tiny=1e-15</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.bic" title="Permalink to this definition">¶</a></dt>
<dd><p>Computation of bic approximation of evidence</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>like, array of shape (n_samples, self.k)</strong></dt><dd><p>component-wise likelihood</p>
</dd>
<dt><strong>tiny=1.e-15, a small constant to avoid numerical singularities</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>the bic value, float</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.check">
<code class="sig-name descname">check</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.check" title="Permalink to this definition">¶</a></dt>
<dd><p>Checking the shape of sifferent matrices involved in the model</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.check_x">
<code class="sig-name descname">check_x</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.check_x" title="Permalink to this definition">¶</a></dt>
<dd><p>essentially check that x.shape[1]==self.dim</p>
<p>x is returned with possibly reshaping</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.conditional_posterior_proba">
<code class="sig-name descname">conditional_posterior_proba</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">perm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.conditional_posterior_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the probability of the current parameters of self
given x and z</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (nb_samples, dim),</strong></dt><dd><p>the data from which bic is computed</p>
</dd>
<dt><strong>z: array of shape (nb_samples), type = np.int,</strong></dt><dd><p>the corresponding classification</p>
</dd>
<dt><strong>perm: array ok shape(nperm, self.k),typ=np.int, optional</strong></dt><dd><p>all permutation of z under which things will be recomputed
By default, no permutation is performed</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.cross_validated_update">
<code class="sig-name descname">cross_validated_update</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">plike</em>, <em class="sig-param">null_class_proba</em>, <em class="sig-param">kfold=10</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.cross_validated_update" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a step in the sampling procedure
that uses internal corss_validation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape(n_samples, dim),</strong></dt><dd><p>the input data</p>
</dd>
<dt><strong>z: array of shape(n_samples),</strong></dt><dd><p>the associated membership variables</p>
</dd>
<dt><strong>plike: array of shape(n_samples),</strong></dt><dd><p>the likelihood under the prior</p>
</dd>
<dt><strong>kfold: int, optional, or array</strong></dt><dd><p>number of folds in cross-validation loop
or set of indexes for the cross-validation procedure</p>
</dd>
<dt><strong>null_class_proba: array of shape(n_samples),</strong></dt><dd><p>prior probability to be under the null</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like: array od shape(n_samples),</strong></dt><dd><p>the (cross-validated) likelihood of the data</p>
</dd>
<dt><strong>z: array of shape(n_samples),</strong></dt><dd><p>the associated membership variables</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>When kfold is an array, there is an internal reshuffling to randomize
the order of updates</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.estimate">
<code class="sig-name descname">estimate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">niter=100</em>, <em class="sig-param">delta=0.0001</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.estimate" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimation of the model given a dataset x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,dim)</strong></dt><dd><p>the data from which the model is estimated</p>
</dd>
<dt><strong>niter=100: maximal number of iterations in the estimation process</strong></dt><dd></dd>
<dt><strong>delta = 1.e-4: increment of data likelihood at which</strong></dt><dd><p>convergence is declared</p>
</dd>
<dt><strong>verbose=0: verbosity mode</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>bic</strong><span class="classifier">an asymptotic approximation of model evidence</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.evidence">
<code class="sig-name descname">evidence</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">nperm=0</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.evidence" title="Permalink to this definition">¶</a></dt>
<dd><p>See bayes_factor(self, x, z, nperm=0, verbose=0)</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.guess_priors">
<code class="sig-name descname">guess_priors</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">nocheck=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.guess_priors" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the priors in order of having them weakly uninformative
this is from  Fraley and raftery;
Journal of Classification 24:155-181 (2007)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x, array of shape (nb_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>nocheck: boolean, optional,</strong></dt><dd><p>if nocheck==True, check is skipped</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.guess_regularizing">
<code class="sig-name descname">guess_regularizing</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">bcheck=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.guess_regularizing" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the regularizing priors as weakly informative
according to Fraley and raftery;
Journal of Classification 24:155-181 (2007)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>initialize z using a k-means algorithm, then upate the parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (nb_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.initialize_and_estimate">
<code class="sig-name descname">initialize_and_estimate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z=None</em>, <em class="sig-param">niter=100</em>, <em class="sig-param">delta=0.0001</em>, <em class="sig-param">ninit=1</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.initialize_and_estimate" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimation of self given x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,dim)</strong></dt><dd><p>the data from which the model is estimated</p>
</dd>
<dt><strong>z = None: array of shape (n_samples)</strong></dt><dd><p>a prior labelling of the data to initialize the computation</p>
</dd>
<dt><strong>niter=100: maximal number of iterations in the estimation process</strong></dt><dd></dd>
<dt><strong>delta = 1.e-4: increment of data likelihood at which</strong></dt><dd><p>convergence is declared</p>
</dd>
<dt><strong>ninit=1: number of initialization performed</strong></dt><dd><p>to reach a good solution</p>
</dd>
<dt><strong>verbose=0: verbosity mode</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>the best model is returned</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.likelihood">
<code class="sig-name descname">likelihood</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">plike=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>return the likelihood of the model for the data x
the values are weighted by the components weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples, self.dim),</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>plike: array os shape (n_samples), optional,x</strong></dt><dd><p>the desnity of each point under the prior</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like, array of shape(nbitem,self.k)</strong></dt><dd></dd>
<dt><strong>component-wise likelihood</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.likelihood_under_the_prior">
<code class="sig-name descname">likelihood_under_the_prior</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.likelihood_under_the_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the likelihood of x under the prior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x, array of shape (self.n_samples,self.dim)</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>w, the likelihood of x under the prior model (unweighted)</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.map_label">
<code class="sig-name descname">map_label</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">like=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.map_label" title="Permalink to this definition">¶</a></dt>
<dd><p>return the MAP labelling of x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,dim)</strong></dt><dd><p>the data under study</p>
</dd>
<dt><strong>like=None array of shape(n_samples,self.k)</strong></dt><dd><p>component-wise likelihood
if like==None, it is recomputed</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>z: array of shape(n_samples): the resulting MAP labelling</strong></dt><dd><p>of the rows of x</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.mixture_likelihood">
<code class="sig-name descname">mixture_likelihood</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.mixture_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the likelihood of the mixture for x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.plugin">
<code class="sig-name descname">plugin</code><span class="sig-paren">(</span><em class="sig-param">means</em>, <em class="sig-param">precisions</em>, <em class="sig-param">weights</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.plugin" title="Permalink to this definition">¶</a></dt>
<dd><p>Set manually the weights, means and precision of the model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>means: array of shape (self.k,self.dim)</strong></dt><dd></dd>
<dt><strong>precisions:  array of shape (self.k,self.dim,self.dim)</strong></dt><dd><p>or (self.k, self.dim)</p>
</dd>
<dt><strong>weights: array of shape (self.k)</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.pop">
<code class="sig-name descname">pop</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.pop" title="Permalink to this definition">¶</a></dt>
<dd><p>compute the population, i.e. the statistics of allocation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>z array of shape (nb_samples), type = np.int</strong></dt><dd><p>the allocation variable</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>hist</strong><span class="classifier">array shape (self.k) count variable</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.probability_under_prior">
<code class="sig-name descname">probability_under_prior</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.probability_under_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the probability of the current parameters of self
given the priors</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.reduce">
<code class="sig-name descname">reduce</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.reduce" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce the assignments by removing empty clusters and update self.k</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>z: array of shape(n),</strong></dt><dd><p>a vector of membership variables changed in place</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>z: the remapped values</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">null_class_proba</em>, <em class="sig-param">niter=1</em>, <em class="sig-param">sampling_points=None</em>, <em class="sig-param">init=False</em>, <em class="sig-param">kfold=None</em>, <em class="sig-param">co_clustering=False</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>sample the indicator and parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples, self.dim),</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>null_class_proba: array of shape(n_samples),</strong></dt><dd><p>the probability to be under the null</p>
</dd>
<dt><strong>niter: int,</strong></dt><dd><p>the number of iterations to perform</p>
</dd>
<dt><strong>sampling_points: array of shape(nbpoints, self.dim), optional</strong></dt><dd><p>points where the likelihood will be sampled
this defaults to x</p>
</dd>
<dt><strong>kfold: int, optional,</strong></dt><dd><p>parameter of cross-validation control
by default, no cross-validation is used
the procedure is faster but less accurate</p>
</dd>
<dt><strong>co_clustering: bool, optional</strong></dt><dd><p>if True,
return a model of data co-labelling across iterations</p>
</dd>
<dt><strong>verbose=0: verbosity mode</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>likelihood: array of shape(nbpoints)</strong></dt><dd><p>total likelihood of the model</p>
</dd>
<dt><strong>pproba: array of shape(n_samples),</strong></dt><dd><p>the posterior of being in the null
(the posterior of null_class_proba)</p>
</dd>
<dt><strong>coclust: only if co_clustering==True,</strong></dt><dd><p>sparse_matrix of shape (n_samples, n_samples),
frequency of co-labelling of each sample pairs
across iterations</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.sample_and_average">
<code class="sig-name descname">sample_and_average</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">niter=1</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.sample_and_average" title="Permalink to this definition">¶</a></dt>
<dd><p>sample the indicator and parameters
the average values for weights,means, precisions are returned</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x = array of shape (nb_samples,dim)</strong></dt><dd><p>the data from which bic is computed</p>
</dd>
<dt><strong>niter=1: number of iterations</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>weights: array of shape (self.k)</strong></dt><dd></dd>
<dt><strong>means: array of shape (self.k,self.dim)</strong></dt><dd></dd>
<dt><strong>precisions:  array of shape (self.k,self.dim,self.dim)</strong></dt><dd><p>or (self.k, self.dim)
these are the average parameters across samplings</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>All this makes sense only if no label switching as occurred so this is
wrong in general (asymptotically).</p>
<p>fix: implement a permutation procedure for components identification</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.sample_indicator">
<code class="sig-name descname">sample_indicator</code><span class="sig-paren">(</span><em class="sig-param">like</em>, <em class="sig-param">null_class_proba</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.sample_indicator" title="Permalink to this definition">¶</a></dt>
<dd><p>sample the indicator from the likelihood</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>like: array of shape (nbitem,self.k)</strong></dt><dd><p>component-wise likelihood</p>
</dd>
<dt><strong>null_class_proba: array of shape(n_samples),</strong></dt><dd><p>prior probability to be under the null</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>z: array of shape(nbitem): a draw of the membership variable</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Here z=-1 encodes for the null class</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.set_constant_densities">
<code class="sig-name descname">set_constant_densities</code><span class="sig-paren">(</span><em class="sig-param">null_dens=None</em>, <em class="sig-param">prior_dens=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.set_constant_densities" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the null and prior densities as constant
(over a  supposedly compact domain)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>null_dens: float, optional</strong></dt><dd><p>constant for the null density</p>
</dd>
<dt><strong>prior_dens: float, optional</strong></dt><dd><p>constant for the prior density</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.set_priors">
<code class="sig-name descname">set_priors</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.set_priors" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the priors in order of having them weakly uninformative
this is from  Fraley and raftery;
Journal of Classification 24:155-181 (2007)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x, array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.show">
<code class="sig-name descname">show</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">gd</em>, <em class="sig-param">density=None</em>, <em class="sig-param">axes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.show" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to plot a GMM, still in progress
Currently, works only in 1D and 2D</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape(n_samples, dim)</strong></dt><dd><p>the data under study</p>
</dd>
<dt><strong>gd: GridDescriptor instance</strong></dt><dd></dd>
<dt><strong>density: array os shape(prod(gd.n_bins))</strong></dt><dd><p>density of the model one the discrete grid implied by gd
by default, this is recomputed</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.show_components">
<code class="sig-name descname">show_components</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">gd</em>, <em class="sig-param">density=None</em>, <em class="sig-param">mpaxes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.show_components" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to plot a GMM – Currently, works only in 1D</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape(n_samples, dim)</strong></dt><dd><p>the data under study</p>
</dd>
<dt><strong>gd: GridDescriptor instance</strong></dt><dd></dd>
<dt><strong>density: array os shape(prod(gd.n_bins))</strong></dt><dd><p>density of the model one the discrete grid implied by gd
by default, this is recomputed</p>
</dd>
<dt><strong>mpaxes: axes handle to make the figure, optional,</strong></dt><dd><p>if None, a new figure is created</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.simple_update">
<code class="sig-name descname">simple_update</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em>, <em class="sig-param">plike</em>, <em class="sig-param">null_class_proba</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.simple_update" title="Permalink to this definition">¶</a></dt>
<dd><p>One step in the sampling procedure (one data sweep)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape(n_samples, dim),</strong></dt><dd><p>the input data</p>
</dd>
<dt><strong>z: array of shape(n_samples),</strong></dt><dd><p>the associated membership variables</p>
</dd>
<dt><strong>plike: array of shape(n_samples),</strong></dt><dd><p>the likelihood under the prior</p>
</dd>
<dt><strong>null_class_proba: array of shape(n_samples),</strong></dt><dd><p>prior probability to be under the null</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like: array od shape(n_samples),</strong></dt><dd><p>the likelihood of the data under the H1 hypothesis</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.test">
<code class="sig-name descname">test</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">tiny=1e-15</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the log-likelihood of the mixture for x</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>ll: array of shape(n_samples)</strong></dt><dd><p>the log-likelihood of the rows of x</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z=None</em>, <em class="sig-param">niter=100</em>, <em class="sig-param">delta=0.0001</em>, <em class="sig-param">ninit=1</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Idem initialize_and_estimate</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.unweighted_likelihood">
<code class="sig-name descname">unweighted_likelihood</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.unweighted_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>return the likelihood of each data for each component
the values are not weighted by the component weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like, array of shape(n_samples,self.k)</strong></dt><dd><p>unweighted component-wise likelihood</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Hopefully faster</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.unweighted_likelihood_">
<code class="sig-name descname">unweighted_likelihood_</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.unweighted_likelihood_" title="Permalink to this definition">¶</a></dt>
<dd><p>return the likelihood of each data for each component
the values are not weighted by the component weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>like, array of shape(n_samples,self.k)</strong></dt><dd><p>unweighted component-wise likelihood</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update function (draw a sample of the IMM parameters)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (n_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>z array of shape (n_samples), type = np.int</strong></dt><dd><p>the corresponding classification</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.update_means">
<code class="sig-name descname">update_means</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.update_means" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the allocation vector z,
and the corresponding data x,
resample the mean</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: array of shape (nb_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>z: array of shape (nb_samples), type = np.int</strong></dt><dd><p>the corresponding classification</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.update_precisions">
<code class="sig-name descname">update_precisions</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.update_precisions" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the allocation vector z,
and the corresponding data x,
resample the precisions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x array of shape (nb_samples,self.dim)</strong></dt><dd><p>the data used in the estimation process</p>
</dd>
<dt><strong>z array of shape (nb_samples), type = np.int</strong></dt><dd><p>the corresponding classification</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.clustering.imm.MixedIMM.update_weights">
<code class="sig-name descname">update_weights</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.MixedIMM.update_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the allocation vector z, resmaple the weights parameter</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>z array of shape (n_samples), type = np.int</strong></dt><dd><p>the allocation variable</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nipy.algorithms.clustering.imm.co_labelling">
<code class="sig-prename descclassname">nipy.algorithms.clustering.imm.</code><code class="sig-name descname">co_labelling</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">kmax=None</em>, <em class="sig-param">kmin=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.co_labelling" title="Permalink to this definition">¶</a></dt>
<dd><p>return a sparse co-labelling matrix given the label vector z</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>z: array of shape(n_samples),</strong></dt><dd><p>the input labels</p>
</dd>
<dt><strong>kmax: int, optional,</strong></dt><dd><p>considers only the labels in the range [0, kmax[</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>colabel: a sparse coo_matrix,</strong></dt><dd><p>yields the co labelling of the data
i.e. c[i,j]= 1 if z[i]==z[j], 0 otherwise</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="nipy.algorithms.clustering.imm.main">
<code class="sig-prename descclassname">nipy.algorithms.clustering.imm.</code><code class="sig-name descname">main</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.clustering.imm.main" title="Permalink to this definition">¶</a></dt>
<dd><p>Illustrative example of the behaviour of imm</p>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="nipy.algorithms.clustering.utils.html" title="algorithms.clustering.utils"
             >next</a> |</li>
        <li class="right" >
          <a href="nipy.algorithms.clustering.hierarchical_clustering.html" title="algorithms.clustering.hierarchical_clustering"
             >previous</a> |</li>
  <li><a href="../../index.html">NIPY home</a> |&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="../../documentation.html" >NIPY documentation</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" >API</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2021, Neuroimaging in Python team.
      Last updated on Mar 29, 2021.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.4.4.
    </div>
  </body>
</html>